{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selecao_caracteristicas.ipynb",
      "provenance": [],
      "mount_file_id": "1oPae4TxxpcHpXGJkT-Rcycrg5m1_YoPp",
      "authorship_tag": "ABX9TyNIeQEsVz5n7BYKEGezjGNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoribeir0/Projetos_Ciencia_de_Dados/blob/main/selecao_caracteristicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx7jGhumhOn_"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "iV0BEZLbFuay",
        "outputId": "d76f0310-58d9-4657-dc05-ecda241daf98"
      },
      "source": [
        "# Caso acontece erro com o import do scikit-learn:\n",
        "!pip uninstall scikit-learn -y\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scikit-learn 1.0\n",
            "Uninstalling scikit-learn-1.0:\n",
            "  Successfully uninstalled scikit-learn-1.0\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC30fRa2bbJI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_wine, load_breast_cancer, load_digits # Imports de diferentes datasets.\n",
        "from sklearn.feature_selection import SelectKBest, VarianceThreshold, f_classif, SequentialFeatureSelector\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from sklearn import tree # Importa o modelo de classificação a ser usado (árvore de decisão)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOibry9ahf2U"
      },
      "source": [
        "## Definindo os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBCuZDgPhkGD"
      },
      "source": [
        "# Aqui pode ser carregado qualquer um dos datasets que foram importados.\n",
        "dados = load_breast_cancer() \n",
        "\n",
        "# Define as entradas (variáveis de entrada).\n",
        "X = dados.data \n",
        "\n",
        "# Define as saídas.\n",
        "Y = dados.target \n",
        "\n",
        "# Define o nome de cada variável.\n",
        "variaveis = dados.feature_names\n",
        "\n",
        "# Normaliza os dados (opcional).\n",
        "min_max = preprocessing.MinMaxScaler()\n",
        "X = min_max.fit_transform(X)\n",
        "\n",
        "# Mostra a descrição do dataset.\n",
        "# print(dados.DESCR)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG9_Ihle6qVt"
      },
      "source": [
        "## Definindo o classificador\n",
        "Essa função é usada para classificar os dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1Muw2PrzqcZ"
      },
      "source": [
        "def arvore(X,Y):\n",
        "  # Sepera os dados em dados de treino e dados de teste.\n",
        "  x_treino, x_teste, y_treino, y_teste = train_test_split(X,\n",
        "                                                          Y,\n",
        "                                                          stratify=Y,\n",
        "                                                          test_size=0.25,\n",
        "                                                          random_state=1)\n",
        "  \n",
        "  # Cria uma instância do modelo de classificação.\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "\n",
        "  # Ajusta o modelo.\n",
        "  clf.fit(x_treino,y_treino)\n",
        "\n",
        "  # Testa e mede a acurácia do modelo com os dados de teste.\n",
        "  y_pred = clf.predict(x_teste)\n",
        "  return  100*np.round(accuracy_score(y_teste, y_pred, normalize=True),3)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxc7IbhimJf2"
      },
      "source": [
        "## Seleção de características (ou variáveis)\n",
        "Aqui serão apresentados três técnicas, todas do módulo de seleção de características do *scikit-learn*.\n",
        "### 1. Seleção de variáveis baseada em variância\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBUqRIB_lJ_F",
        "outputId": "d0a044b1-6e64-4ffd-934f-6090282f4473"
      },
      "source": [
        "# Valor mínimo para as variâncias (esse valor é escolhido pelo usuário e depende do conjunto de dados, é importate testar com vários valores).\n",
        "minimo = 0.02\n",
        "vt = VarianceThreshold(minimo) \n",
        "\n",
        "# Redução das variáveis de acordo com a variância (X_novo terá menos variáveis que o X).\n",
        "X_novo = vt.fit_transform(X) \n",
        "\n",
        "# Determina as variâncias para cada variável em X.\n",
        "variancias = vt.fit(X,Y)\n",
        "\n",
        "# Cria um DataFrame com as variâncias e para as variáveis.\n",
        "df_scores = pd.DataFrame(variancias.variances_)\n",
        "df_var = pd.DataFrame(variaveis)\n",
        "\n",
        "# Concatena os dois DataFrames e adiciona os nomes das colunas.\n",
        "df_var = pd.concat([df_var,df_scores], axis=1)\n",
        "df_var.columns = ['Característica','Variância']\n",
        "\n",
        "# Mostra o DataFrame com todas a características e suas variâncias.\n",
        "# print(df_var)\n",
        "print('\\n')\n",
        "\n",
        "# Mantém somente as características que são maiores que o minimo e remove as outras.\n",
        "filtro = df_var['Variância'] >= minimo\n",
        "df_var.where(filtro, inplace = True)\n",
        "df_var = df_var.dropna()\n",
        "\n",
        "# Mostra o DataFrame com somentes as características que possuem variâncias maiores que o limite.\n",
        "print(df_var.nlargest(X_novo.shape[1],'Variância'))\n",
        "\n",
        "# Mostra o número inicial de variáveis e o número final (reduzido).\n",
        "print('\\n')\n",
        "print('Número inicial de variáveis: ' + str(X.shape[1]))\n",
        "print('Número final de variáveis: ' + str(X_novo.shape[1]))\n",
        "print('\\n')\n",
        "\n",
        "# Mostra os resultados obtidos, com os dados não reduzidos e com os dados reduzidos.\n",
        "print('Acurácia:')\n",
        "print('Acurácia (dados não reduzidos): ' + str(arvore(X,Y)) + '% | ' + 'Acurácia (dados reduzidos): ' + str(arvore(X_novo,Y)) + '%')\n",
        "print('Classificador: Árvore de Decisão')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "            Característica  Variância\n",
            "27    worst concave points   0.050934\n",
            "7      mean concave points   0.037128\n",
            "6           mean concavity   0.034827\n",
            "20            worst radius   0.029512\n",
            "2           mean perimeter   0.028146\n",
            "22         worst perimeter   0.027957\n",
            "0              mean radius   0.027769\n",
            "26         worst concavity   0.027718\n",
            "21           worst texture   0.026787\n",
            "5         mean compactness   0.026195\n",
            "25       worst compactness   0.023261\n",
            "24        worst smoothness   0.022694\n",
            "3                mean area   0.022244\n",
            "9   mean fractal dimension   0.022073\n",
            "1             mean texture   0.021119\n",
            "\n",
            "\n",
            "Número inicial de variáveis: 30\n",
            "Número final de variáveis: 15\n",
            "\n",
            "\n",
            "Acurácia:\n",
            "Acurácia (dados não reduzidos): 93.7% | Acurácia (dados reduzidos): 93.7%\n",
            "Classificador: Árvore de Decisão\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS3ATP-OmV9L"
      },
      "source": [
        "### 2. Seleção baseada em scores de variáveis (SelectKBest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzb1rU7vmR9r",
        "outputId": "72a090ae-3bc7-46d5-ac26-b1ea2c0ac94d"
      },
      "source": [
        "# Inicia o seletor de variáveis, k = número de variáveis que serão selecionadas.\n",
        "K = 6\n",
        "k_melhores = SelectKBest(f_classif, k=K)\n",
        "\n",
        "# Redução das variáveis de acordo com a variância (X_novo terá menos variáveis que o X).\n",
        "X_novo = k_melhores.fit_transform(X,Y)\n",
        "\n",
        "# Determina o score para as variáveis.\n",
        "scores = k_melhores.fit(X,Y)\n",
        "\n",
        "# Cria um DataFrame com os scores e para as variáveis.\n",
        "df_scores2 = pd.DataFrame(scores.scores_)\n",
        "df_var2 = pd.DataFrame(variaveis)\n",
        "\n",
        "# Concatena os dois DataFrames e adiciona os nomes das colunas.\n",
        "df_var2 = pd.concat([df_var2,df_scores2], axis=1)\n",
        "df_var2.columns = ['Característica','Score']\n",
        "\n",
        "# Mostra o DataFrame com todas a características e suas variâncias.\n",
        "# print(df_var2)\n",
        "print('\\n')\n",
        "\n",
        "# Mostra o DataFrame com somentes as k características com maior score.\n",
        "print(df_var2.nlargest(K,'Score'))\n",
        "print('\\n')\n",
        "\n",
        "# Mostra os resultados obtidos, com os dados não reduzidos e com os dados reduzidos.\n",
        "print('Acurácia:')\n",
        "print('Acurácia (dados não reduzidos): ' + str(arvore(X,Y)) + '% | ' + 'Acurácia (dados reduzidos): ' + str(arvore(X_novo,Y)) + '%')\n",
        "print('Classificador: Árvore de Decisão')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "          Característica       Score\n",
            "27  worst concave points  964.385393\n",
            "22       worst perimeter  897.944219\n",
            "7    mean concave points  861.676020\n",
            "20          worst radius  860.781707\n",
            "2         mean perimeter  697.235272\n",
            "23            worst area  661.600206\n",
            "\n",
            "\n",
            "Acurácia:\n",
            "Acurácia (dados não reduzidos): 93.0% | Acurácia (dados reduzidos): 95.1%\n",
            "Classificador: Árvore de Decisão\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syNxoN096Gqx"
      },
      "source": [
        "### 3. Seleção sequencial de varíaveis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF03OQEG6Urz",
        "outputId": "2245226d-e00d-4af5-8d68-e148761bc116"
      },
      "source": [
        "# Define o classificador a ser usado.\n",
        "modelo = tree.DecisionTreeClassifier()\n",
        "\n",
        "# Inicia o seletor de variáveis, n_features_to_select = número de variáveis que serão selecionadas.\n",
        "sfs = SequentialFeatureSelector(modelo, n_features_to_select = 5)\n",
        "sfs.fit(X, Y)\n",
        "\n",
        "# Redução das variáveis de acordo com a variância (X_novo terá menos variáveis que o X).\n",
        "X_novo = sfs.transform(X)\n",
        "\n",
        "# Mostra quais variáveis foram selecionadas.\n",
        "var = np.array(variaveis)\n",
        "print('Variáveis selecionadas:')\n",
        "print(var[sfs.get_support()])\n",
        "print('\\n')\n",
        "\n",
        "# Mostra os resultados obtidos, com os dados não reduzidos e com os dados reduzidos.\n",
        "print('Acurácia:')\n",
        "print('Acurácia (dados não reduzidos): ' + str(arvore(X,Y)) + '% | ' + 'Acurácia (dados reduzidos): ' + str(arvore(X_novo,Y)) + '%')\n",
        "print('Classificador: Árvore de Decisão')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variáveis selecionadas:\n",
            "['mean texture' 'mean compactness' 'texture error' 'worst radius'\n",
            " 'worst concave points']\n",
            "\n",
            "\n",
            "Acurácia:\n",
            "Acurácia (dados não reduzidos): 94.0% | Acurácia (dados reduzidos): 95.0%\n",
            "Classificador: Árvore de Decisão\n"
          ]
        }
      ]
    }
  ]
}
